# sslearn

WORK IN PROGRESS

Examples of usage can be found in folder `examples`.

TODO:
* Major refactors
* Optimizations

Pretraining models:
- [ ] Colorization
- [ ] CPC
- [x] MoCo
- [x] SimCLR
- [x] SwAV
- [x] DINO
- [x] BYOL
- [ ] SimSiam
- [x] Barlow Twins

# References

1. [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) (ResNet)

2. [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) (ViT)

3. [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722) (MoCo)

4. [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) (SimCLR)

5. [Unsupervised Learning of Visual Features by Contrasting Cluster Assignments](https://arxiv.org/abs/2006.09882) (SwAV)

6. [Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294) (DINO)

7. [Bootstrap your own latent: A new approach to self-supervised Learning](https://arxiv.org/abs/2006.07733) (BYOL)

8. [Barlow Twins: Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/abs/2103.03230) (Barlow Twins)
